{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a6c1b3",
   "metadata": {},
   "source": [
    "# ECC Assignement 2 - Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e050b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367f051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/12 09:08:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/12 09:08:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[2]\") \\\n",
    "      .appName(\"SparkByExamples.com\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999a55f",
   "metadata": {},
   "source": [
    "## NYC Parking Violation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c8070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyc = spark.read.format(\"csv\").load(\"Parking_Violations_Issued_-_Fiscal_Year_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cf7b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/12 09:08:43 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0='Summons Number', _c1='Plate ID', _c2='Registration State', _c3='Plate Type', _c4='Issue Date', _c5='Violation Code', _c6='Vehicle Body Type', _c7='Vehicle Make', _c8='Issuing Agency', _c9='Street Code1', _c10='Street Code2', _c11='Street Code3', _c12='Vehicle Expiration Date', _c13='Violation Location', _c14='Violation Precinct', _c15='Issuer Precinct', _c16='Issuer Code', _c17='Issuer Command', _c18='Issuer Squad', _c19='Violation Time', _c20='Time First Observed', _c21='Violation County', _c22='Violation In Front Of Or Opposite', _c23='House Number', _c24='Street Name', _c25='Intersecting Street', _c26='Date First Observed', _c27='Law Section', _c28='Sub Division', _c29='Violation Legal Code', _c30='Days Parking In Effect    ', _c31='From Hours In Effect', _c32='To Hours In Effect', _c33='Vehicle Color', _c34='Unregistered Vehicle?', _c35='Vehicle Year', _c36='Meter Number', _c37='Feet From Curb', _c38='Violation Post Code', _c39='Violation Description', _c40='No Standing or Stopping Violation', _c41='Hydrant Violation', _c42='Double Parking Violation')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nyc.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d214617e",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "### When are tickets most likely to be issued?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b9116",
   "metadata": {},
   "source": [
    "The question states at what time of the day the tickets are issued and total number of tickets issued at that particular time \n",
    "\n",
    "To solve the question we just use the groupby function in pyspark on the \"Violation time\" and count the number of ticket issued at that particular time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6042e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyc_q1 = df_nyc.groupBy(\"_c19\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f144a5",
   "metadata": {},
   "source": [
    "Once the new dataframe is created of violation time and the count of ticket issued at that paritcular time I arranged it in descending order and display the top 5 time when ticket was issued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c09755a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 times when ticket are most likely issued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----------------------+\n",
      "|Time when ticket was issued|Total number of tickets|\n",
      "+---------------------------+-----------------------+\n",
      "|                      0836A|                  12003|\n",
      "|                      0906A|                  11394|\n",
      "|                      0838A|                  11281|\n",
      "|                      0839A|                  11270|\n",
      "|                      0840A|                  11202|\n",
      "+---------------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nyc_q1 = df_nyc_q1.sort(desc(\"count\"))\n",
    "print(\"Top 5 times when ticket are most likely issued\")\n",
    "df_nyc_q1 = df_nyc_q1.select(col(\"_c19\").alias(\"Time when ticket was issued\"), col(\"count\").alias(\"Total number of tickets\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f079b069",
   "metadata": {},
   "source": [
    "The output shown above lists the top 5 situations in NYC when(time) a ticket is be issued. It displays two columns: one for the violation time, or \"when,\" the ticket is issued, and the other for the violation count, or the total number of tickets issued at that time. According to this table, we may deduce that the most tickets were probably issued at 0836A with a count of 12003."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5902c",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### What are the most common years and types of cars to be ticketed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32405839",
   "metadata": {},
   "source": [
    "The question states that, the year or \"Vehicle Year\" and the type or \"Vehicle Type\" acting like a single parameter are the most ticketed \n",
    "\n",
    "To solve the question I calculated the count of Vehicle Type and Vehicle Year as a single parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "683e0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyc_q2 = df_nyc.na.drop(subset=[\"_c6\"]).withColumn(\"_c35\", df_nyc[\"_c35\"].cast(IntegerType())).filter(\"_c35 > 0\")\n",
    "df_nyc_q2 = df_nyc_q2.groupBy(\"_c6\", \"_c35\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e95699",
   "metadata": {},
   "source": [
    "Once the count is done I sorted the new table in descending order and displayed the top 20 Vehicle type and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f367410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most common Vehicle Type and Years: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------------+\n",
      "|Vehicle Type|Vehicle Year|Violation Count|\n",
      "+------------+------------+---------------+\n",
      "|        SUBN|        2021|         302579|\n",
      "|        SUBN|        2020|         254398|\n",
      "|        SUBN|        2019|         229424|\n",
      "|        SUBN|        2022|         213913|\n",
      "|        SUBN|        2018|         177057|\n",
      "|        SUBN|        2017|         144410|\n",
      "|        SUBN|        2016|         116255|\n",
      "|        4DSD|        2017|         111780|\n",
      "|        SUBN|        2015|         110579|\n",
      "|        4DSD|        2018|         109220|\n",
      "|        4DSD|        2019|         106716|\n",
      "|        4DSD|        2020|          98466|\n",
      "|        4DSD|        2021|          88997|\n",
      "|        4DSD|        2015|          88408|\n",
      "|        4DSD|        2016|          88097|\n",
      "|        SUBN|        2014|          84805|\n",
      "|        SUBN|        2013|          78531|\n",
      "|        4DSD|        2022|          71645|\n",
      "|        SUBN|        2011|          71071|\n",
      "|        4DSD|        2013|          70461|\n",
      "+------------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nyc_q2 = df_nyc_q2.sort(desc(\"count\"))\n",
    "print(\"Top 20 most common Vehicle Type and Years: \")\n",
    "df_nyc_q2 = df_nyc_q2.select(col(\"_c6\").alias(\"Vehicle Type\"), col(\"_c35\").alias(\"Vehicle Year\"), col(\"count\").alias(\"Violation Count\")).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6eccaf",
   "metadata": {},
   "source": [
    "The output shown above lists the top 20 years and car types for which tickets were issued. The first column in this table lists the kind of the vehicle that received a ticket, the second lists the typical years when tickets were issued, and the third gives the total number of tickets issued in relation to the first two columns. We deduce from the data that the SUBN vehicle type received tickets 302579 times  in 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cdfe98",
   "metadata": {},
   "source": [
    "## Question 3 \n",
    "### Where are tickets most commonly issued? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1039dbe",
   "metadata": {},
   "source": [
    "The question states at what location of the day the tickets are issued and total number of tickets issued at that particular location\n",
    "\n",
    "\n",
    "To solve the question we just use the groupby function in pyspark on the \"Violation location\" and count the number of ticket issued at that particular location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4801038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyc_q3 = df_nyc.na.drop(subset=[\"_c13\"])\n",
    "df_nyc_q3 = df_nyc_q3.groupBy(\"_c13\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ed4a1",
   "metadata": {},
   "source": [
    "Once the new dataframe is created of violation lcoation and the count of ticket issued at that paritcular location I arranged it in descending order and display the top 10 location when ticket was issued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47f1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common Violation Location: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+\n",
      "|Violation Location|Violation Count|\n",
      "+------------------+---------------+\n",
      "|              0013|         146695|\n",
      "|              0019|         142982|\n",
      "|              0006|         119458|\n",
      "|               114|         111627|\n",
      "|              0014|         102973|\n",
      "|              0018|          99891|\n",
      "|              0009|          86819|\n",
      "|              0001|          86580|\n",
      "|               108|          64908|\n",
      "|              0020|          63996|\n",
      "+------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nyc_q3 = df_nyc_q3.sort(desc(\"count\"))\n",
    "print(\"Top 10 most common Violation Location: \")\n",
    "df_nyc_q3 = df_nyc_q3.select(col(\"_c13\").alias(\"Violation Location\"), col(\"count\").alias(\"Violation Count\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576c0c74",
   "metadata": {},
   "source": [
    "The output shown above lists the top 10 situations in NYC where(location) a ticket is be issued. It displays two columns: one for the violation location, or \"where,\" the ticket is issued, and the other for the violation count, or the total number of tickets issued at that location. According to this table, we may deduce that the most tickets were probably issued at 0013 with a count of 146695."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a72ee7",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### Which color of the vehicle is most likely to get a ticket? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46ddd8",
   "metadata": {},
   "source": [
    "The question states which color of the vehicle is most likely to get a ticket\n",
    "\n",
    "To solve the question we just use the groupby function in pyspark on the \"Vehicle Color\" and count the number of ticket issued for that particular color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe7f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyc_q4 = df_nyc.na.drop(subset=[\"_c33\"])\n",
    "df_nyc_q4 = df_nyc_q4.groupBy(\"_c33\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595cefed",
   "metadata": {},
   "source": [
    "Once the new dataframe is created of Vehicle Color and the count of ticket issued for that paritcular color, I arranged it in descending order and display the top 10 vehicle color for which the ticket was issued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b492afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common Vehicle Color to get a ticket: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|Vehicle Color|Violation Count|\n",
      "+-------------+---------------+\n",
      "|           GY|        1204214|\n",
      "|           WH|        1100147|\n",
      "|           BK|        1056412|\n",
      "|           BL|         404706|\n",
      "|        WHITE|         363462|\n",
      "|           RD|         233608|\n",
      "|        BLACK|         221080|\n",
      "|         GREY|         157773|\n",
      "|         BLUE|          81232|\n",
      "|        BROWN|          79706|\n",
      "+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nyc_q4 = df_nyc_q4.sort(desc(\"count\"))\n",
    "print(\"Top 10 most common Vehicle Color to get a ticket: \")\n",
    "df_nyc_q4 = df_nyc_q4.select(col(\"_c33\").alias(\"Vehicle Color\"), col(\"count\").alias(\"Violation Count\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415a43b",
   "metadata": {},
   "source": [
    "The output shown above lists the top 10 vehicle color in NYC for which a ticket is be issued. It displays two columns: one for the vehicle color, or \"which color,\" the ticket is issued, and the other for the violation count, or the total number of tickets issued for that particular color. According to this table, we may deduce that the most tickets were issued for Grey(GY) with a count of 1204214."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4fedd",
   "metadata": {},
   "source": [
    "## NBA Shots Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "048230c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba = spark.read.format(\"csv\").load(\"shot_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d472b23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='GAME_ID', _c1='MATCHUP', _c2='LOCATION', _c3='W', _c4='FINAL_MARGIN', _c5='SHOT_NUMBER', _c6='PERIOD', _c7='GAME_CLOCK', _c8='SHOT_CLOCK', _c9='DRIBBLES', _c10='TOUCH_TIME', _c11='SHOT_DIST', _c12='PTS_TYPE', _c13='SHOT_RESULT', _c14='CLOSEST_DEFENDER', _c15='CLOSEST_DEFENDER_PLAYER_ID', _c16='CLOSE_DEF_DIST', _c17='FGM', _c18='PTS', _c19='player_name', _c20='player_id')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ac8c7",
   "metadata": {},
   "source": [
    "## Question 1 (NBA)\n",
    "\n",
    "### For each pair of the players (A, B), we define the fear sore of A when facing B is the hit rate, such that B is closet defender when A is shooting. Based on the fear sore, for each player, please find out who is his ”most unwanted defender”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dc676",
   "metadata": {},
   "source": [
    "The below step involves the grouping of columns Player ID and Defender ID and counts the total number of hits - 1's and no hits - 0's in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19c86c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_cond = lambda cond: sum(when(cond, 1).otherwise(0))\n",
    "df_nba_q1 = df_nba.groupBy(col(\"_c20\").alias(\"PlayerID\"), col(\"_c15\").alias(\"DefenderID\")) .agg(cnt_cond(col(\"_c13\") == \"made\").alias(\"count1s\"), cnt_cond(col(\"_c13\") == \"missed\").alias(\"count0s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4089e53",
   "metadata": {},
   "source": [
    "The block below involves the calculation of the hit rate. 1's denotes if goes inside the basket hits and 0's denotes no basket. Thus, it follows the formula of hits/total number of hits [hits + no hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aecb5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_q1 = df_nba_q1.withColumn(\"HitRate\", col=col(\"count1s\")/(col(\"count1s\") + col(\"count0s\")))\n",
    "df_nba_q1 = df_nba_q1.na.drop(subset=[\"HitRate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f501511f",
   "metadata": {},
   "source": [
    "The block below drops the duplicates of PlayerID and HitRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f41791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_q1 = df_nba_q1.dropDuplicates([\"PlayerID\", \"HitRate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b309e10",
   "metadata": {},
   "source": [
    "The block below involves finding the minimum value of hit rate for each Player ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80a5b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_q11 = df_nba_q1.groupBy(\"PlayerID\").agg({\"HitRate\": \"min\"}).withColumn(\"HitRate\", col(\"min(HitRate)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd4962",
   "metadata": {},
   "source": [
    "Finally, I joined the two columns i.e., Player ID and Defender ID, drop duplicates in them and display the output of Players along with their most unwanted defenders based on the value generated from the Hit Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3271a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+\n",
      "|       Player Name|Most Unwanted Defender|\n",
      "+------------------+----------------------+\n",
      "|      andrew bogut|         Hinrich, Kirk|\n",
      "|   marvin williams|      Fredette, Jimmer|\n",
      "|        chris paul|      Carroll, DeMarre|\n",
      "|charlie villanueva|     Cousins, DeMarcus|\n",
      "|     channing frye|       Roberson, Andre|\n",
      "|    deron williams|                  Nene|\n",
      "|      gerald green|        Leonard, Kawhi|\n",
      "|     nate robinson|          Williams, Mo|\n",
      "|      jarrett jack|     Parsons, Chandler|\n",
      "|     jason maxiell|  Caldwell-Pope, Ke...|\n",
      "+------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nba_q1 = df_nba_q1.join(df_nba_q11, [\"PlayerID\", \"HitRate\"]).select(\"PlayerID\", \"DefenderID\")\n",
    "df_nba_q1 = df_nba_q1.join(df_nba, [df_nba[\"_c20\"] == df_nba_q1[\"PlayerID\"], df_nba[\"_c15\"] == df_nba_q1[\"DefenderID\"]]).withColumn(\"Player Name\", col(\"_c19\")).withColumn(\"Most Unwanted Defender\", col(\"_c14\")).dropDuplicates([\"PlayerID\", \"DefenderID\"]).select(\"Player Name\", \"Most Unwanted Defender\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3162231d",
   "metadata": {},
   "source": [
    "In this problem, the hit rate is used to define each player's fear score while they are facing their opponent, so that the opponent is the player's closest defence when the player is firing. The top 10 most despised defenders are shown in the above table for each player based on their fear score. We can conclude that Kirk Hinrich is the least desired defender for the player Andrew Bogut, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228b06b",
   "metadata": {},
   "source": [
    "## Question 2 (NBA)\n",
    "\n",
    "### Please develop a Spark-based algorithm to classify each player’s records into 4 comfortable zones. Considering the hit rate, which zone is the best for James Harden, Chris Paul,Stephen Curry, and Lebron James"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb09b3e",
   "metadata": {},
   "source": [
    "The block below involves the grouping of columns Player ID and Shot Distance, ColestDefDistance and ShotClock and counts the total number of hits - 1's and no hits - 0's in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecb55b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_cond = lambda cond: sum(when(cond, 1).otherwise(0))\n",
    "df_nba_q2 = df_nba.groupBy(col(\"_c20\").alias(\"PlayerID\"), col(\"_c11\").alias(\"ShotDistance\"), col(\"_c16\").alias(\"ClosestDefDistance\"), col(\"_c8\").alias(\"ShotClock\")).agg(cnt_cond(col(\"_c13\") == \"made\").alias(\"count1s\"), cnt_cond(col(\"_c13\") == \"missed\").alias(\"count0s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d74c9",
   "metadata": {},
   "source": [
    "The block below involves the calculation of the hit rate. 1's denotes if the hits and 0's denotes no hits. Thus, it follows the formula of hits/total number of hits [hits + no hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "315dbaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_q2 = df_nba_q2.withColumn(\"HitRate\", col=col(\"count1s\")/(col(\"count1s\") + col(\"count0s\")))\n",
    "df_nba_q2 = df_nba_q2.na.drop(subset=[\"HitRate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b7b93",
   "metadata": {},
   "source": [
    "The block below drops the duplicates of PlayerID and HitRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "173cb5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_q2 = df_nba_q2.dropDuplicates([\"PlayerID\", \"HitRate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb008e",
   "metadata": {},
   "source": [
    "The block below involves finding the minimum value of hit rate for each Player ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "466b91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_q22 = df_nba_q2.groupBy(\"PlayerID\").agg({\"HitRate\": \"min\"}).withColumn(\"HitRate\", col(\"min(HitRate)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4db6b",
   "metadata": {},
   "source": [
    "Finally, we use join generate the Closest Def Distance, Shot Clock and shot distance for 4 secific players based on their hit rate. This step involves grouping columns and dropping duplicate values whereever necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25803272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_q2 = df_nba_q2.join(df_nba_q22, [\"PlayerID\", \"HitRate\"]).select(\"PlayerID\", \"ShotDistance\", \"ClosestDefDistance\", \"ShotClock\")\n",
    "df_nba_q2 = df_nba_q2.join(df_nba, [df_nba[\"_c20\"] == df_nba_q2[\"PlayerID\"]]) \\\n",
    "    .withColumn(\"Player Name\", col(\"_c19\")).withColumn(\"Shot Distance\", col(\"ShotDistance\")) \\\n",
    "    .withColumn(\"Closest Def Distance\", col(\"ClosestDefDistance\")).withColumn(\"Shot Clock\", col(\"ShotClock\")) \\\n",
    "    .dropDuplicates([\"PlayerID\", \"Closest Def Distance\", \"Shot Clock\", \"Shot Distance\"]) \\\n",
    "    .select(\"Player Name\", \"Closest Def Distance\", \"Shot Clock\", \"Shot Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89515198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+----------+-------------+\n",
      "| Player Name|Closest Def Distance|Shot Clock|Shot Distance|\n",
      "+------------+--------------------+----------+-------------+\n",
      "|lebron james|                 3.7|      10.3|         19.5|\n",
      "+------------+--------------------+----------+-------------+\n",
      "\n",
      "+------------+--------------------+----------+-------------+\n",
      "| Player Name|Closest Def Distance|Shot Clock|Shot Distance|\n",
      "+------------+--------------------+----------+-------------+\n",
      "|james harden|                 2.9|      12.0|         14.1|\n",
      "+------------+--------------------+----------+-------------+\n",
      "\n",
      "+-----------+--------------------+----------+-------------+\n",
      "|Player Name|Closest Def Distance|Shot Clock|Shot Distance|\n",
      "+-----------+--------------------+----------+-------------+\n",
      "| chris paul|                 0.4|      null|         22.7|\n",
      "+-----------+--------------------+----------+-------------+\n",
      "\n",
      "+-------------+--------------------+----------+-------------+\n",
      "|  Player Name|Closest Def Distance|Shot Clock|Shot Distance|\n",
      "+-------------+--------------------+----------+-------------+\n",
      "|stephen curry|                 3.7|      14.5|         19.1|\n",
      "+-------------+--------------------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bestZoneForPlayer(playerName, df):\n",
    "    df.where(col(\"Player Name\") == playerName).show()\n",
    "\n",
    "for names in [\"lebron james\", \"james harden\", \"chris paul\", \"stephen curry\"]:\n",
    "    bestZoneForPlayer(names, df_nba_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961026d2",
   "metadata": {},
   "source": [
    "In this question, we establish the shooting comfort zone for each player as a matrix of \"SHOT DIST, CLOSE DEF DIST, SHOT CLOCK.\" The optimum zone for players like Lebron James, James Harden, Chris Paul, and Stephen Curry is determined by the output's hit rate. The four tables display the closest defensive distance, shot clock, and shooting distance with respect to each of the four players based on the essential parameters and hit rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640851fa",
   "metadata": {},
   "source": [
    "# END OF ASSIGNMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
